#!/usr/bin/env python3

"""infer the parameters of the model based on the data
"""
__author__ = "Reed Essick (reed.essick@gmail.com)"

#-------------------------------------------------

import h5py

import numpy as np

import jax
from jax import random
from jax import numpy as jnp
from jax.scipy.special import logsumexp

import numpyro
import numpyro.distributions as dist
from numpyro.infer import (MCMC, NUTS)

#-------------------------------------------------

seed = 123 # pick a random seed to make result reproducible

#-------------------------------------------------

# load data

data = np.genfromtxt('data.csv.gz', names=True, delimiter=',')

num_samp = len(data)
num_dim = len(data.dtype.names) - 2

improved = data['obs']
features = np.transpose([data['feature_%03d'%_] for _ in range(num_dim)])

#------------------------

# build a model

def model(num_dim, features, improved):

    # draw priors for coefficients
    coeffs = numpyro.sample("coeffs", dist.Uniform(-10.0, +10.0), sample_shape=(num_dim+1,))

    # compute probabilities
    logprobs = numpyro.deterministic("logprobs", -jnp.log(1+jnp.exp(coeffs[0] + jnp.sum(features*coeffs[1:], axis=1))))
    logprobs_unimproved = jnp.log(1-jnp.exp(logprobs))

    # add target distribution as a factor
    numpyro.factor("logprob", jnp.sum(improved*logprobs + (1-improved)*logprobs_unimproved))

#------------------------

# sample from that model

# instantiate the sampler
mcmc = MCMC(NUTS(model), num_warmup=500, num_samples=10000)

# run the sample
mcmc.run(random.PRNGKey(seed), num_dim, features, improved)
samples = mcmc.get_samples()

# record the likelihood of each sample
samples.update(numpyro.infer.log_likelihood(model, samples, num_dim, features, improved))

mcmc.print_summary()

#------------------------

# save the output

with h5py.File('samples.hdf', 'w') as obj:

    obj.attrs.create('num_samp', data=num_samp)
    obj.attrs.create('num_dim', data=num_dim)

    for key, val in samples.items():
        obj.create_dataset(key, data=val)
